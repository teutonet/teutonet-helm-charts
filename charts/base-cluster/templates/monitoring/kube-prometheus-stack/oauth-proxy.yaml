{{- if and .Values.global.authentication.config .Values.monitoring.prometheus.enabled }}
{{- $backends := list -}}
{{- if include "base-cluster.monitoring.authenticated-ingress.enabled" (dict "name" "prometheus" "context" .) -}}
  {{- $backends = append $backends (dict "host" "prometheus" "port" 9090) -}}
{{- end -}}
{{- if and (include "base-cluster.prometheus-stack.alertmanager.enabled" .) (include "base-cluster.monitoring.authenticated-ingress.enabled" (dict "name" "alertmanager" "context" .)) -}}
  {{- $backends = append $backends (dict "host" "alertmanager" "port" 9093) -}}
{{- end -}}
{{- range $backend := $backends }}
  {{- $host := $backend.host -}}
  {{- $port := $backend.port -}}
  {{- $targetServiceName := printf "%s-%s" (include "common.names.dependency.fullname" (dict "chartName" "kube-prometheus-stack" "chartValues" (dict) "context" (dict "Release" (dict "Name" "kube-prometheus-stack")))) $host -}}
  {{- $ingress := include "base-cluster.monitoring.ingress.config" (dict "name" $host "context" $) | fromYaml -}}
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: {{ printf "cluster-%s-oauth-proxy" $host }}
  namespace: monitoring
  labels: {{- include "common.labels.standard" $ | nindent 4 }}
    app.kubernetes.io/component: oauth-proxy
    app.kubernetes.io/part-of: {{ $host }}
spec:
  chart:
    spec: {{- include "base-cluster.helm.chartSpec" (dict "repo" "bitnami" "chart" "oauth2-proxy" "context" $) | nindent 6 }}
  interval: 1h
  driftDetection:
    mode: enabled
  values:
    redis:
      enabled: false
  {{- if $.Values.global.imageRegistry }}
    global:
      imageRegistry: {{ $.Values.global.imageRegistry }}
  {{- end }}
    ingress:
      enabled: true
      hostname: {{ include (printf "base-cluster.%s.host" $host) $ }}
      tls: true
      {{- if $.Values.dns.provider }}
      selfSigned: true # `certManager: true` leads to overwritten wildcard certificates
      {{- else }}
      certManager: true
      {{- end }}
      existingSecretName: {{ include "base-cluster.certificate" (dict "name" $host "customDomain" $ingress.customDomain "context" $) | quote }}
    replicaCount: 2
    pdb:
      create: true
      minAvailable: 1
      maxUnavailable: ""
    podSecurityContext:
      enabled: true
    containerSecurityContext:
      enabled: true
    resources: {{- include "common.resources" $.Values.global.authentication.oauthProxy | nindent 6 }}
    configuration:
      existingSecret: {{ include "common.secrets.name" (dict "defaultNameSuffix" "oauth-proxy" "context" $) }}
      content: |-
        provider = "oidc"
        reverse_proxy = true
        oidc_issuer_url = {{ printf "https://%s%s" $.Values.global.authentication.config.issuerHost $.Values.global.authentication.config.issuerPath | quote }}
        skip_provider_button = true
        {{- if $.Values.global.authentication.oauthProxy.emailDomains }}
        email_domains = [ "{{ $.Values.global.authentication.oauthProxy.emailDomains | join "\", \"" }}" ]
        {{- else }}
        email_domains = "*"
        {{- end }}
        upstreams = [ {{ printf "http://%s:%d" $targetServiceName $port | quote }} ]
    podAnnotations:
      # This might change on every `template` call, this can be ignored
      checksum/secret: {{ include "common.utils.checksumTemplate" (dict "path" "/monitoring/kube-prometheus-stack/oauth-proxy-secret.yaml" "context" $) }}
{{- if eq (include "common.networkPolicy.type" $) "cilium" }}
---
apiVersion: cilium.io/v2
kind: CiliumNetworkPolicy
metadata:
  name: {{ printf "cluster-%s-oauth-proxy" $host }}
  namespace: monitoring
  labels: {{- include "common.labels.standard" $ | nindent 4 }}
    app.kubernetes.io/component: oauth
    app.kubernetes.io/part-of: {{ $host }}
spec:
  endpointSelector:
    matchLabels:
      app.kubernetes.io/instance: {{ printf "monitoring-cluster-%s-oauth-proxy" $host }}
  ingress:
    - fromEndpoints:
        - matchLabels: {{- include "common.tplvalues.render" (dict "value" $.Values.global.networkPolicy.ingressLabels "context" $) | nindent 12 }}
      toPorts:
        - ports:
            - port: "4180"
              protocol: TCP
  egress:
    - toEndpoints:
        - matchLabels:
            app.kubernetes.io/name: {{ $host | quote }}
            io.kubernetes.pod.namespace: monitoring
      toPorts:
        - ports:
            - port: {{ $port | quote }}
              protocol: TCP
    - toFQDNs:
        - matchName: {{ $.Values.global.authentication.config.issuerHost | quote }}
      toPorts:
        - ports:
            - port: "443"
              protocol: TCP
    - toEndpoints:
        - matchLabels: {{- include "common.tplvalues.render" (dict "value" $.Values.global.networkPolicy.dnsLabels "context" $) | nindent 12 }}
      toPorts:
        - ports:
            - port: "53"
              protocol: UDP
          rules:
            dns:
              - matchName: {{ $.Values.global.authentication.config.issuerHost | quote }}
{{- end }}
---
{{- end }}
{{- end }}
